{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C192SOmJS6lw"
      },
      "source": [
        "# CS 195: Natural Language Processing\n",
        "## Introduction to the Hugging Face Transformers Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tE8azY-yKN_"
      },
      "source": [
        "## References\n",
        "\n",
        "Hugging Face *Quicktour*: https://huggingface.co/docs/transformers/quicktour\n",
        "\n",
        "Hugging Face *Run Inference with Pipelines tutorial*: https://huggingface.co/docs/transformers/pipeline_tutorial\n",
        "\n",
        "Hugging Face *NLP Course, Chapter 2*: https://huggingface.co/learn/nlp-course/chapter2/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPLu03OeyKOA"
      },
      "source": [
        "## Announcement: Venture Capital Panels\n",
        "\n",
        "From Kevin Croft (Director of the Kelley Center for Insurance Innovation):\n",
        "\n",
        "Do you know a student interested in innovation, starting a business, or with great tech solutions who would like to learn from those who’ve done it before?  The Kelley Center for Insurance Innovation invites you and your students to two opportunities to engage with business accelerators and venture capital investors.  Please share this information with your students!\n",
        " * On Wednesday, September 27 at 4 pm in Aliber 101 the leaders of the Global Insurance Accelerator and BrokerTech Ventures will form a panel to discuss how accelerators work, the application/acceptance process, the mentorship process, and success stories from their accelerators.   \n",
        " * On Wednesday, October 4 at 4 pm in Aliber 101 Wellabe Ventures, ManchesterStory, and Homesteaders Life will form a panel to discuss their approach to private equity investing in innovation partners.  The discussion will include identification/selection of target firms, the evaluation process, goals of the investment, and success stories.\n",
        "\n",
        "I hope to see you there!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qL3tRokyKOB"
      },
      "source": [
        "## The Plan\n",
        "\n",
        "The first thing we're going to do is get comfortable with the Hugging Face *Transformers* library for Python\n",
        "\n",
        "Eventual goals:\n",
        "* understand and explain how transformer models work\n",
        "* create and adapt transformers for a specific purpose\n",
        "\n",
        "For now:\n",
        "* learn to *use* existing transformer models\n",
        "* understand *what* they can do\n",
        "* get a feel for pupular families of models and how they're related\n",
        "\n",
        "We will dig into the internals later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFKO9Q6myKOB"
      },
      "source": [
        "## What is Hugging Face?\n",
        "\n",
        "Hugging Face is a private company\n",
        "* Founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf\n",
        "* Based in New York City\n",
        "\n",
        "Provide a popular free, open-source Python library called **transformers** for NLP (and other) tasks\n",
        "\n",
        "Host *hundreds of thousands of models* that you can use in your own programs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTKPXNVnyKOC"
      },
      "source": [
        "## Installing the transformers module\n",
        "\n",
        "This is my favored way of installing packages from a Jupyter Notebook\n",
        "\n",
        "If you have lots of Python distributions installed, it should use the right one\n",
        "\n",
        "It may take a few minutes, but *you should only have to do this once*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtzh7PJvyKOC",
        "outputId": "ed27c664-29c4-4afb-8526-cec54a124e37",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.10/site-packages (4.32.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/elijahlueders/Library/Python/3.10/lib/python/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from transformers) (3.12.3)\n",
            "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/elijahlueders/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8eyeIW5yKOE"
      },
      "source": [
        "## Using the sentiment analysis pipeline\n",
        "\n",
        "**Sentiment analysis** attempts to identify the overall feeling intended by the writer of some text\n",
        "\n",
        "The creators of this model **trained** it on lots of examples of text that were labeled as either *positive* or *negative*\n",
        "\n",
        "A **pipeline** is a series of steps for performing **inference**\n",
        "* tokenize and preprocess the input text (more on this later)\n",
        "* ask the model for a prediction\n",
        "* post-process model's result and turn it into something you can use\n",
        "\n",
        "![full_nlp_pipeline.svg](https://github.com/ericmanley/f23-CS195NLP/blob/main/images/full_nlp_pipeline.svg?raw=1)\n",
        "image source: https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gaF19zByKOE"
      },
      "source": [
        "We *are* specifying the kind of task: `sentiment-analysis`\n",
        "\n",
        "We *are not* asking for a specific model, so it picks one of many it has by default\n",
        "\n",
        "The first time you do this, it will have to download the model - this can take some time depending on your network connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORPo9HgwyKOE",
        "outputId": "da01b35a-4589-4bc5-f06c-2d227ff89ffb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9984305500984192}]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "classifier(\"I love how easy it is to build sentiment-aware applications with the transformers library!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzYZ2F0qyKOF"
      },
      "source": [
        "**Test it out:** Try changing the input to get different labels/scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrZ4dOmzyKOF"
      },
      "source": [
        "## Working with batches of text\n",
        "\n",
        "To get classifications of many different examples, pass in a list of strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwMN6QtQyKOF",
        "outputId": "e6e90c5b-fc16-4dbd-965e-e1e03505c288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9991173148155212}, {'label': 'NEGATIVE', 'score': 0.9557347297668457}, {'label': 'NEGATIVE', 'score': 0.9962737560272217}]\n"
          ]
        }
      ],
      "source": [
        "results = classifier([\"It's really cool that you can get classifications for a whole batch of text\",\n",
        "                      \"I wonder if the rest of the class will be this easy.\",\n",
        "                     \"Spolier alert: it won't be.\"])\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HQSVdYRyKOF"
      },
      "source": [
        "Note that the results come back as a list of dictionaries, so you can manipulate it in the normal ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osrgIU8DyKOF",
        "outputId": "bd80bf86-cce8-4fb3-807c-8a1b9a0ffc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentence had POSITIVE sentiment, with a score of 0.9991173148155212\n"
          ]
        }
      ],
      "source": [
        "print(\"The sentence had\",results[0][\"label\"],\"sentiment, with a score of\",results[0][\"score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4hNiCpdyKOG"
      },
      "source": [
        "## Exercise: Specifying a model\n",
        "\n",
        "Now try asking for a specific model.\n",
        "\n",
        "Replace one line of code in your earlier example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OkjIBTClyKOG"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Could not load model SamLowe/roberta-base-go_emotions with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.roberta.modeling_tf_roberta.TFRobertaForSequenceClassification'>).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classifier \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39msentiment-analysis\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSamLowe/roberta-base-go_emotions\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/transformers/pipelines/__init__.py:807\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    806\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 807\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    808\u001b[0m         model,\n\u001b[1;32m    809\u001b[0m         model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    810\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    811\u001b[0m         framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    812\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    813\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    815\u001b[0m     )\n\u001b[1;32m    817\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    818\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/transformers/pipelines/base.py:276\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 276\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     framework \u001b[39m=\u001b[39m infer_framework(model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Could not load model SamLowe/roberta-base-go_emotions with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.roberta.modeling_tf_roberta.TFRobertaForSequenceClassification'>)."
          ]
        }
      ],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRoNuEwyKOG"
      },
      "source": [
        "How is this model different from the first model?\n",
        "\n",
        "Create a cell in this notebook and note the differences you see"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnq810FMzsci",
        "outputId": "9d9e96c0-b118-45e5-b8d5-5fb225a5d068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'neutral', 'score': 0.9344079494476318}, {'label': 'admiration', 'score': 0.5409085750579834}, {'label': 'surprise', 'score': 0.7312608957290649}, {'label': 'neutral', 'score': 0.7667409181594849}, {'label': 'neutral', 'score': 0.5689737200737}]\n"
          ]
        }
      ],
      "source": [
        "text_list= [\n",
        "    \"Dogs are mammals.\",\n",
        "    \"It's really cool that you can get classifications for a whole batch of text\",\n",
        "    \"I wonder if the rest of the class will be this easy.\",\n",
        "    \"Spolier alert: it won't be.\",\n",
        "    \"Today is Thursday.\",\n",
        "    ]\n",
        "results = classifier(text_list)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvnTgX6mX4FT",
        "outputId": "57e37a3a-8f69-4995-ff39-955e44379cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Dogs are mammals.' was labeled neutral with a score of 0.9344079494476318\n",
            "'It's really cool that you can get classifications for a whole batch of text' was labeled admiration with a score of 0.5409085750579834\n",
            "'I wonder if the rest of the class will be this easy.' was labeled surprise with a score of 0.7312608957290649\n",
            "'Spolier alert: it won't be.' was labeled neutral with a score of 0.7667409181594849\n",
            "'Today is Thursday.' was labeled neutral with a score of 0.5689737200737\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(text_list)):\n",
        "  print(f\"'{text_list[i]}' was labeled {results[i]['label']} with a score of {results[i]['score']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z42s0ayOdeY4"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"The quarterly financial report is showing an improvements this quarter.\",  # Incorrect\n",
        "    \"Him has completed the audit for last fiscal year.\",  # Incorrect\n",
        "    \"Please to inform the board about the recent developments.\",  # Incorrect\n",
        "    \"The team successfully achieved all its targets for the last quarter.\",  # Correct\n",
        "    \"Our company is exploring new ventures in the European market.\"  # Correct\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiOuV478dq_n",
        "outputId": "9187d186-f4ec-4201-bfae-1a9c8b6a5f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'label': 'LABEL_0', 'score': 0.5484333038330078}\n",
            "{'label': 'LABEL_0', 'score': 0.6328231692314148}\n",
            "{'label': 'LABEL_0', 'score': 0.542167067527771}\n",
            "{'label': 'LABEL_0', 'score': 0.7175154685974121}\n",
            "{'label': 'LABEL_0', 'score': 0.6996312141418457}\n"
          ]
        }
      ],
      "source": [
        "results = pipe(sentences)\n",
        "for i in range(len(results)):\n",
        "\n",
        "  print(results[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSd6Rb75Ymlp"
      },
      "source": [
        "There are different/more labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6qn4tW-yKOG"
      },
      "source": [
        "## Applied Exploration\n",
        "\n",
        "The `roberta-base-go_emotions` model is documented here: https://huggingface.co/SamLowe/roberta-base-go_emotions\n",
        "\n",
        "Answer some questions about this:\n",
        "* What is `roberta-base`? Write down some things you can learn about it from the documentation.\n",
        "* What is `go_emotions`? Write down some things you can learn about it from the documentation.\n",
        "\n",
        "Go to the Hugging Face models page: https://huggingface.co/models\n",
        "* click `Text Classification`\n",
        "* Try some additional models\n",
        "    - test out at least one more sentiment/emotions model\n",
        "    - test out at least two other kinds of models - like news topic classification or spam detection\n",
        "    - write down some info about the models you found\n",
        "        - what is it for?\n",
        "        - who made it?\n",
        "        - what kind of data was it trained on?\n",
        "        - are they based on some other model and trained on new data (*fine-tuned*) for a specific task?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
