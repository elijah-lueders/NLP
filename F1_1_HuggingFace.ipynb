{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C192SOmJS6lw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS 195: Natural Language Processing\n",
    "## Introduction to the Hugging Face Transformers Library\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/f23-CS195NLP/blob/main/F1_1_HuggingFace.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "Hugging Face *Quicktour*: https://huggingface.co/docs/transformers/quicktour\n",
    "\n",
    "Hugging Face *Run Inference with Pipelines tutorial*: https://huggingface.co/docs/transformers/pipeline_tutorial\n",
    "\n",
    "Hugging Face *NLP Course, Chapter 2*: https://huggingface.co/learn/nlp-course/chapter2/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Announcement: Venture Capital Panels\n",
    "\n",
    "From Kevin Croft (Director of the Kelley Center for Insurance Innovation):\n",
    "\n",
    "Do you know a student interested in innovation, starting a business, or with great tech solutions who would like to learn from those who’ve done it before?  The Kelley Center for Insurance Innovation invites you and your students to two opportunities to engage with business accelerators and venture capital investors.  Please share this information with your students!\n",
    " * On Wednesday, September 27 at 4 pm in Aliber 101 the leaders of the Global Insurance Accelerator and BrokerTech Ventures will form a panel to discuss how accelerators work, the application/acceptance process, the mentorship process, and success stories from their accelerators.   \n",
    " * On Wednesday, October 4 at 4 pm in Aliber 101 Wellabe Ventures, ManchesterStory, and Homesteaders Life will form a panel to discuss their approach to private equity investing in innovation partners.  The discussion will include identification/selection of target firms, the evaluation process, goals of the investment, and success stories.\n",
    " \n",
    "I hope to see you there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Plan\n",
    "\n",
    "The first thing we're going to do is get comfortable with the Hugging Face *Transformers* library for Python\n",
    "\n",
    "Eventual goals:\n",
    "* understand and explain how transformer models work\n",
    "* create and adapt transformers for a specific purpose\n",
    "\n",
    "For now:\n",
    "* learn to *use* existing transformer models\n",
    "* understand *what* they can do\n",
    "* get a feel for pupular families of models and how they're related\n",
    "\n",
    "We will dig into the internals later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Hugging Face?\n",
    "\n",
    "Hugging Face is a private company\n",
    "* Founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf\n",
    "* Based in New York City\n",
    "\n",
    "Provide a popular free, open-source Python library called **transformers** for NLP (and other) tasks\n",
    "\n",
    "Host *hundreds of thousands of models* that you can use in your own programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing the transformers module\n",
    "\n",
    "This is my favored way of installing packages from a Jupyter Notebook\n",
    "\n",
    "If you have lots of Python distributions installed, it should use the right one\n",
    "\n",
    "It may take a few minutes, but *you should only have to do this once*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (3.8.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (2.28.1)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-macosx_12_0_arm64.whl (406 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (1.23.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.8.8-cp310-cp310-macosx_11_0_arm64.whl (289 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.3.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (2022.6.15)\n",
      "Installing collected packages: tokenizers, safetensors, tqdm, regex, fsspec, huggingface-hub, transformers\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/Users/000794593/Library/Python/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/Users/000794593/Library/Python/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/Users/000794593/Library/Python/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 tqdm-4.66.1 transformers-4.32.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.10/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the sentiment analysis pipeline\n",
    "\n",
    "**Sentiment analysis** attempts to identify the overall feeling intended by the writer of some text\n",
    "\n",
    "The creators of this model **trained** it on lots of examples of text that were labeled as either *positive* or *negative*\n",
    "\n",
    "A **pipeline** is a series of steps for performing **inference**\n",
    "* tokenize and preprocess the input text (more on this later)\n",
    "* ask the model for a prediction\n",
    "* post-process model's result and turn it into something you can use\n",
    "\n",
    "![full_nlp_pipeline.svg](images/full_nlp_pipeline.svg)\n",
    "image source: https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We *are* specifying the kind of task: `sentiment-analysis`\n",
    "\n",
    "We *are not* asking for a specific model, so it picks one of many it has by default\n",
    "\n",
    "The first time you do this, it will have to download the model - this can take some time depending on your network connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9984305500984192}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "classifier(\"I love how easy it is to build sentiment-aware applications with the transformers library!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test it out:** Try changing the input to get different labels/scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with batches of text\n",
    "\n",
    "To get classifications of many different examples, pass in a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9991173148155212}, {'label': 'NEGATIVE', 'score': 0.9557351469993591}, {'label': 'NEGATIVE', 'score': 0.9962737560272217}]\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"It's really cool that you can get classifications for a whole batch of text\",\n",
    "                      \"I wonder if the rest of the class will be this easy.\",\n",
    "                     \"Spolier alert: it won't be.\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the results come back as a list of dictionaries, so you can manipulate it in the normal ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence had POSITIVE sentiment, with a score of 0.9991173148155212\n"
     ]
    }
   ],
   "source": [
    "print(\"The sentence had\",results[0][\"label\"],\"sentiment, with a score of\",results[0][\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: Specifying a model\n",
    "\n",
    "Now try asking for a specific model. \n",
    "\n",
    "Replace one line of code in your earlier example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is this model different from the first model? \n",
    "\n",
    "Create a cell in this notebook and note the differences you see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applied Exploration\n",
    "\n",
    "The `roberta-base-go_emotions` model is documented here: https://huggingface.co/SamLowe/roberta-base-go_emotions\n",
    "\n",
    "Answer some questions about this:\n",
    "* What is `roberta-base`? Write down some things you can learn about it from the documentation.\n",
    "* What is `go_emotions`? Write down some things you can learn about it from the documentation.\n",
    "\n",
    "Go to the Hugging Face models page: https://huggingface.co/models\n",
    "* click `Text Classification`\n",
    "* Try some additional models\n",
    "    - test out at least one more sentiment/emotions model\n",
    "    - test out at least two other kinds of models - like news topic classification or spam detection\n",
    "    - write down some info about the models you found\n",
    "        - what is it for?\n",
    "        - who made it?\n",
    "        - what kind of data was it trained on?\n",
    "        - are they based on some other model and trained on new data (*fine-tuned*) for a specific task?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOf2oi4GbgdvkO0orSdgZtQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
